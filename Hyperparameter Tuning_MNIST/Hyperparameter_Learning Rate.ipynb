{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Learning Rate: 0.0001\n",
      "Epoch 1/50 - Train Loss: 0.9361, Val Loss: 0.4699\n",
      "Epoch 2/50 - Train Loss: 0.4278, Val Loss: 0.3471\n",
      "Epoch 3/50 - Train Loss: 0.3444, Val Loss: 0.2991\n",
      "Epoch 4/50 - Train Loss: 0.2950, Val Loss: 0.2621\n",
      "Epoch 5/50 - Train Loss: 0.2658, Val Loss: 0.2422\n",
      "Epoch 6/50 - Train Loss: 0.2439, Val Loss: 0.2223\n",
      "Epoch 7/50 - Train Loss: 0.2213, Val Loss: 0.2098\n",
      "Epoch 8/50 - Train Loss: 0.2049, Val Loss: 0.1991\n",
      "Epoch 9/50 - Train Loss: 0.1909, Val Loss: 0.1874\n",
      "Epoch 10/50 - Train Loss: 0.1787, Val Loss: 0.1811\n",
      "Epoch 11/50 - Train Loss: 0.1704, Val Loss: 0.1704\n",
      "Epoch 12/50 - Train Loss: 0.1600, Val Loss: 0.1681\n",
      "Epoch 13/50 - Train Loss: 0.1526, Val Loss: 0.1610\n",
      "Epoch 14/50 - Train Loss: 0.1462, Val Loss: 0.1554\n",
      "Epoch 15/50 - Train Loss: 0.1402, Val Loss: 0.1484\n",
      "Epoch 16/50 - Train Loss: 0.1322, Val Loss: 0.1470\n",
      "Epoch 17/50 - Train Loss: 0.1274, Val Loss: 0.1406\n",
      "Epoch 18/50 - Train Loss: 0.1235, Val Loss: 0.1388\n",
      "Epoch 19/50 - Train Loss: 0.1197, Val Loss: 0.1367\n",
      "Epoch 20/50 - Train Loss: 0.1154, Val Loss: 0.1337\n",
      "Epoch 21/50 - Train Loss: 0.1096, Val Loss: 0.1337\n",
      "Epoch 22/50 - Train Loss: 0.1039, Val Loss: 0.1342\n",
      "Epoch 23/50 - Train Loss: 0.1042, Val Loss: 0.1306\n",
      "Epoch 24/50 - Train Loss: 0.0992, Val Loss: 0.1318\n",
      "Epoch 25/50 - Train Loss: 0.0975, Val Loss: 0.1278\n",
      "Epoch 26/50 - Train Loss: 0.0971, Val Loss: 0.1265\n",
      "Epoch 27/50 - Train Loss: 0.0930, Val Loss: 0.1205\n",
      "Epoch 28/50 - Train Loss: 0.0885, Val Loss: 0.1224\n",
      "Epoch 29/50 - Train Loss: 0.0895, Val Loss: 0.1254\n",
      "Epoch 30/50 - Train Loss: 0.0838, Val Loss: 0.1211\n",
      "Epoch 31/50 - Train Loss: 0.0818, Val Loss: 0.1188\n",
      "Epoch 32/50 - Train Loss: 0.0810, Val Loss: 0.1205\n",
      "Epoch 33/50 - Train Loss: 0.0767, Val Loss: 0.1166\n",
      "Epoch 34/50 - Train Loss: 0.0780, Val Loss: 0.1170\n",
      "Epoch 35/50 - Train Loss: 0.0763, Val Loss: 0.1152\n",
      "Epoch 36/50 - Train Loss: 0.0738, Val Loss: 0.1192\n",
      "Epoch 37/50 - Train Loss: 0.0718, Val Loss: 0.1156\n",
      "Epoch 38/50 - Train Loss: 0.0693, Val Loss: 0.1146\n",
      "Epoch 39/50 - Train Loss: 0.0691, Val Loss: 0.1159\n",
      "Epoch 40/50 - Train Loss: 0.0669, Val Loss: 0.1150\n",
      "Epoch 41/50 - Train Loss: 0.0661, Val Loss: 0.1163\n",
      "Epoch 42/50 - Train Loss: 0.0641, Val Loss: 0.1145\n",
      "Epoch 43/50 - Train Loss: 0.0618, Val Loss: 0.1116\n",
      "Epoch 44/50 - Train Loss: 0.0601, Val Loss: 0.1160\n",
      "Epoch 45/50 - Train Loss: 0.0608, Val Loss: 0.1096\n",
      "Epoch 46/50 - Train Loss: 0.0596, Val Loss: 0.1130\n",
      "Epoch 47/50 - Train Loss: 0.0583, Val Loss: 0.1124\n",
      "Epoch 48/50 - Train Loss: 0.0569, Val Loss: 0.1099\n",
      "Epoch 49/50 - Train Loss: 0.0586, Val Loss: 0.1113\n",
      "Epoch 50/50 - Train Loss: 0.0560, Val Loss: 0.1084\n",
      "Learning Rate 0.0001: Test Accuracy: 96.92%\n",
      "\n",
      "Training with Learning Rate: 0.0005\n",
      "Epoch 1/50 - Train Loss: 0.0738, Val Loss: 0.1229\n",
      "Epoch 2/50 - Train Loss: 0.0729, Val Loss: 0.1172\n",
      "Epoch 3/50 - Train Loss: 0.0694, Val Loss: 0.1186\n",
      "Epoch 4/50 - Train Loss: 0.0621, Val Loss: 0.1127\n",
      "Epoch 5/50 - Train Loss: 0.0614, Val Loss: 0.1188\n",
      "Epoch 6/50 - Train Loss: 0.0579, Val Loss: 0.1232\n",
      "Epoch 7/50 - Train Loss: 0.0556, Val Loss: 0.1210\n",
      "Epoch 8/50 - Train Loss: 0.0502, Val Loss: 0.1124\n",
      "Epoch 9/50 - Train Loss: 0.0482, Val Loss: 0.1148\n",
      "Epoch 10/50 - Train Loss: 0.0448, Val Loss: 0.1134\n",
      "Epoch 11/50 - Train Loss: 0.0458, Val Loss: 0.1157\n",
      "Epoch 12/50 - Train Loss: 0.0433, Val Loss: 0.1154\n",
      "Epoch 13/50 - Train Loss: 0.0410, Val Loss: 0.1073\n",
      "Epoch 14/50 - Train Loss: 0.0380, Val Loss: 0.1177\n",
      "Epoch 15/50 - Train Loss: 0.0355, Val Loss: 0.1186\n",
      "Epoch 16/50 - Train Loss: 0.0368, Val Loss: 0.1172\n",
      "Epoch 17/50 - Train Loss: 0.0361, Val Loss: 0.1162\n",
      "Epoch 18/50 - Train Loss: 0.0349, Val Loss: 0.1131\n",
      "Epoch 19/50 - Train Loss: 0.0324, Val Loss: 0.1073\n",
      "Epoch 20/50 - Train Loss: 0.0345, Val Loss: 0.1199\n",
      "Epoch 21/50 - Train Loss: 0.0333, Val Loss: 0.1223\n",
      "Epoch 22/50 - Train Loss: 0.0317, Val Loss: 0.1159\n",
      "Epoch 23/50 - Train Loss: 0.0298, Val Loss: 0.1230\n",
      "Epoch 24/50 - Train Loss: 0.0285, Val Loss: 0.1104\n",
      "Epoch 25/50 - Train Loss: 0.0277, Val Loss: 0.1181\n",
      "Epoch 26/50 - Train Loss: 0.0291, Val Loss: 0.1163\n",
      "Epoch 27/50 - Train Loss: 0.0272, Val Loss: 0.1097\n",
      "Epoch 28/50 - Train Loss: 0.0259, Val Loss: 0.1158\n",
      "Epoch 29/50 - Train Loss: 0.0264, Val Loss: 0.1134\n",
      "Epoch 30/50 - Train Loss: 0.0262, Val Loss: 0.1171\n",
      "Epoch 31/50 - Train Loss: 0.0260, Val Loss: 0.1207\n",
      "Epoch 32/50 - Train Loss: 0.0245, Val Loss: 0.1071\n",
      "Epoch 33/50 - Train Loss: 0.0229, Val Loss: 0.1085\n",
      "Epoch 34/50 - Train Loss: 0.0215, Val Loss: 0.1236\n",
      "Epoch 35/50 - Train Loss: 0.0224, Val Loss: 0.1167\n",
      "Epoch 36/50 - Train Loss: 0.0222, Val Loss: 0.1115\n",
      "Epoch 37/50 - Train Loss: 0.0227, Val Loss: 0.1174\n",
      "Epoch 38/50 - Train Loss: 0.0208, Val Loss: 0.1143\n",
      "Epoch 39/50 - Train Loss: 0.0216, Val Loss: 0.1195\n",
      "Epoch 40/50 - Train Loss: 0.0219, Val Loss: 0.1208\n",
      "Epoch 41/50 - Train Loss: 0.0205, Val Loss: 0.1212\n",
      "Epoch 42/50 - Train Loss: 0.0211, Val Loss: 0.1182\n",
      "Epoch 43/50 - Train Loss: 0.0191, Val Loss: 0.1224\n",
      "Epoch 44/50 - Train Loss: 0.0195, Val Loss: 0.1222\n",
      "Epoch 45/50 - Train Loss: 0.0206, Val Loss: 0.1230\n",
      "Epoch 46/50 - Train Loss: 0.0193, Val Loss: 0.1139\n",
      "Epoch 47/50 - Train Loss: 0.0174, Val Loss: 0.1262\n",
      "Epoch 48/50 - Train Loss: 0.0184, Val Loss: 0.1231\n",
      "Epoch 49/50 - Train Loss: 0.0173, Val Loss: 0.1265\n",
      "Epoch 50/50 - Train Loss: 0.0181, Val Loss: 0.1169\n",
      "Learning Rate 0.0005: Test Accuracy: 97.27%\n",
      "\n",
      "Training with Learning Rate: 0.001\n",
      "Epoch 1/50 - Train Loss: 0.0348, Val Loss: 0.1479\n",
      "Epoch 2/50 - Train Loss: 0.0391, Val Loss: 0.1313\n",
      "Epoch 3/50 - Train Loss: 0.0359, Val Loss: 0.1159\n",
      "Epoch 4/50 - Train Loss: 0.0339, Val Loss: 0.1261\n",
      "Epoch 5/50 - Train Loss: 0.0332, Val Loss: 0.1307\n",
      "Epoch 6/50 - Train Loss: 0.0300, Val Loss: 0.1403\n",
      "Epoch 7/50 - Train Loss: 0.0318, Val Loss: 0.1259\n",
      "Epoch 8/50 - Train Loss: 0.0279, Val Loss: 0.1365\n",
      "Epoch 9/50 - Train Loss: 0.0303, Val Loss: 0.1178\n",
      "Epoch 10/50 - Train Loss: 0.0285, Val Loss: 0.1304\n",
      "Epoch 11/50 - Train Loss: 0.0275, Val Loss: 0.1198\n",
      "Epoch 12/50 - Train Loss: 0.0253, Val Loss: 0.1344\n",
      "Epoch 13/50 - Train Loss: 0.0233, Val Loss: 0.1458\n",
      "Epoch 14/50 - Train Loss: 0.0257, Val Loss: 0.1312\n",
      "Epoch 15/50 - Train Loss: 0.0230, Val Loss: 0.1362\n",
      "Epoch 16/50 - Train Loss: 0.0252, Val Loss: 0.1328\n",
      "Epoch 17/50 - Train Loss: 0.0230, Val Loss: 0.1326\n",
      "Epoch 18/50 - Train Loss: 0.0236, Val Loss: 0.1265\n",
      "Epoch 19/50 - Train Loss: 0.0217, Val Loss: 0.1302\n",
      "Epoch 20/50 - Train Loss: 0.0210, Val Loss: 0.1427\n",
      "Epoch 21/50 - Train Loss: 0.0214, Val Loss: 0.1297\n",
      "Epoch 22/50 - Train Loss: 0.0209, Val Loss: 0.1342\n",
      "Epoch 23/50 - Train Loss: 0.0170, Val Loss: 0.1310\n",
      "Epoch 24/50 - Train Loss: 0.0218, Val Loss: 0.1338\n",
      "Epoch 25/50 - Train Loss: 0.0212, Val Loss: 0.1323\n",
      "Epoch 26/50 - Train Loss: 0.0198, Val Loss: 0.1467\n",
      "Epoch 27/50 - Train Loss: 0.0203, Val Loss: 0.1333\n",
      "Epoch 28/50 - Train Loss: 0.0198, Val Loss: 0.1344\n",
      "Epoch 29/50 - Train Loss: 0.0188, Val Loss: 0.1330\n",
      "Epoch 30/50 - Train Loss: 0.0191, Val Loss: 0.1284\n",
      "Epoch 31/50 - Train Loss: 0.0186, Val Loss: 0.1304\n",
      "Epoch 32/50 - Train Loss: 0.0194, Val Loss: 0.1406\n",
      "Epoch 33/50 - Train Loss: 0.0195, Val Loss: 0.1253\n",
      "Epoch 34/50 - Train Loss: 0.0173, Val Loss: 0.1324\n",
      "Epoch 35/50 - Train Loss: 0.0168, Val Loss: 0.1361\n",
      "Epoch 36/50 - Train Loss: 0.0187, Val Loss: 0.1254\n",
      "Epoch 37/50 - Train Loss: 0.0180, Val Loss: 0.1344\n",
      "Epoch 38/50 - Train Loss: 0.0153, Val Loss: 0.1285\n",
      "Epoch 39/50 - Train Loss: 0.0154, Val Loss: 0.1420\n",
      "Epoch 40/50 - Train Loss: 0.0158, Val Loss: 0.1308\n",
      "Epoch 41/50 - Train Loss: 0.0180, Val Loss: 0.1391\n",
      "Epoch 42/50 - Train Loss: 0.0188, Val Loss: 0.1347\n",
      "Epoch 43/50 - Train Loss: 0.0156, Val Loss: 0.1422\n",
      "Epoch 44/50 - Train Loss: 0.0164, Val Loss: 0.1309\n",
      "Epoch 45/50 - Train Loss: 0.0157, Val Loss: 0.1448\n",
      "Epoch 46/50 - Train Loss: 0.0144, Val Loss: 0.1373\n",
      "Epoch 47/50 - Train Loss: 0.0168, Val Loss: 0.1298\n",
      "Epoch 48/50 - Train Loss: 0.0141, Val Loss: 0.1294\n",
      "Epoch 49/50 - Train Loss: 0.0154, Val Loss: 0.1381\n",
      "Epoch 50/50 - Train Loss: 0.0144, Val Loss: 0.1418\n",
      "Learning Rate 0.001: Test Accuracy: 97.32%\n",
      "\n",
      "Training with Learning Rate: 0.005\n",
      "Epoch 1/50 - Train Loss: 0.2878, Val Loss: 0.2246\n",
      "Epoch 2/50 - Train Loss: 0.2061, Val Loss: 0.2076\n",
      "Epoch 3/50 - Train Loss: 0.1882, Val Loss: 0.2437\n",
      "Epoch 4/50 - Train Loss: 0.1750, Val Loss: 0.2121\n",
      "Epoch 5/50 - Train Loss: 0.1617, Val Loss: 0.2202\n",
      "Epoch 6/50 - Train Loss: 0.1510, Val Loss: 0.2527\n",
      "Epoch 7/50 - Train Loss: 0.1427, Val Loss: 0.2300\n",
      "Epoch 8/50 - Train Loss: 0.1476, Val Loss: 0.2104\n",
      "Epoch 9/50 - Train Loss: 0.1425, Val Loss: 0.2115\n",
      "Epoch 10/50 - Train Loss: 0.1344, Val Loss: 0.2151\n",
      "Epoch 11/50 - Train Loss: 0.1238, Val Loss: 0.1861\n",
      "Epoch 12/50 - Train Loss: 0.1260, Val Loss: 0.1841\n",
      "Epoch 13/50 - Train Loss: 0.1349, Val Loss: 0.2324\n",
      "Epoch 14/50 - Train Loss: 0.1379, Val Loss: 0.2151\n",
      "Epoch 15/50 - Train Loss: 0.1266, Val Loss: 0.2033\n",
      "Epoch 16/50 - Train Loss: 0.1088, Val Loss: 0.2322\n",
      "Epoch 17/50 - Train Loss: 0.1195, Val Loss: 0.2032\n",
      "Epoch 18/50 - Train Loss: 0.1181, Val Loss: 0.3490\n",
      "Epoch 19/50 - Train Loss: 0.1200, Val Loss: 0.2391\n",
      "Epoch 20/50 - Train Loss: 0.1195, Val Loss: 0.2212\n",
      "Epoch 21/50 - Train Loss: 0.1090, Val Loss: 0.2010\n",
      "Epoch 22/50 - Train Loss: 0.1215, Val Loss: 0.2365\n",
      "Epoch 23/50 - Train Loss: 0.1131, Val Loss: 0.2135\n",
      "Epoch 24/50 - Train Loss: 0.1137, Val Loss: 0.2308\n",
      "Epoch 25/50 - Train Loss: 0.1238, Val Loss: 0.2635\n",
      "Epoch 26/50 - Train Loss: 0.1105, Val Loss: 0.2226\n",
      "Epoch 27/50 - Train Loss: 0.1247, Val Loss: 0.2053\n",
      "Epoch 28/50 - Train Loss: 0.1070, Val Loss: 0.2229\n",
      "Epoch 29/50 - Train Loss: 0.1076, Val Loss: 0.2309\n",
      "Epoch 30/50 - Train Loss: 0.1134, Val Loss: 0.2274\n",
      "Epoch 31/50 - Train Loss: 0.1215, Val Loss: 0.2332\n",
      "Epoch 32/50 - Train Loss: 0.1164, Val Loss: 0.2269\n",
      "Epoch 33/50 - Train Loss: 0.1244, Val Loss: 0.2053\n",
      "Epoch 34/50 - Train Loss: 0.1164, Val Loss: 0.2890\n",
      "Epoch 35/50 - Train Loss: 0.1116, Val Loss: 0.2418\n",
      "Epoch 36/50 - Train Loss: 0.1103, Val Loss: 0.2425\n",
      "Epoch 37/50 - Train Loss: 0.1125, Val Loss: 0.2253\n",
      "Epoch 38/50 - Train Loss: 0.1140, Val Loss: 0.2210\n",
      "Epoch 39/50 - Train Loss: 0.1158, Val Loss: 0.2378\n",
      "Epoch 40/50 - Train Loss: 0.1066, Val Loss: 0.2007\n",
      "Epoch 41/50 - Train Loss: 0.1121, Val Loss: 0.2485\n",
      "Epoch 42/50 - Train Loss: 0.1172, Val Loss: 0.2014\n",
      "Epoch 43/50 - Train Loss: 0.1009, Val Loss: 0.2399\n",
      "Epoch 44/50 - Train Loss: 0.1248, Val Loss: 0.2362\n",
      "Epoch 45/50 - Train Loss: 0.1106, Val Loss: 0.2481\n",
      "Epoch 46/50 - Train Loss: 0.1091, Val Loss: 0.2518\n",
      "Epoch 47/50 - Train Loss: 0.1113, Val Loss: 0.2367\n",
      "Epoch 48/50 - Train Loss: 0.1103, Val Loss: 0.2548\n",
      "Epoch 49/50 - Train Loss: 0.1131, Val Loss: 0.2394\n",
      "Epoch 50/50 - Train Loss: 0.1114, Val Loss: 0.2260\n",
      "Learning Rate 0.005: Test Accuracy: 95.74%\n",
      "\n",
      "Training with Learning Rate: 0.01\n",
      "Epoch 1/50 - Train Loss: 2.1031, Val Loss: 2.3156\n",
      "Epoch 2/50 - Train Loss: 2.3094, Val Loss: 2.3072\n",
      "Epoch 3/50 - Train Loss: 2.3093, Val Loss: 2.3225\n",
      "Epoch 4/50 - Train Loss: 2.3084, Val Loss: 2.3107\n",
      "Epoch 5/50 - Train Loss: 2.3098, Val Loss: 2.3056\n",
      "Epoch 6/50 - Train Loss: 2.3094, Val Loss: 2.3126\n",
      "Epoch 7/50 - Train Loss: 2.3087, Val Loss: 2.3097\n",
      "Epoch 8/50 - Train Loss: 2.3089, Val Loss: 2.3048\n",
      "Epoch 9/50 - Train Loss: 2.3095, Val Loss: 2.3068\n",
      "Epoch 10/50 - Train Loss: 2.3092, Val Loss: 2.3058\n",
      "Epoch 11/50 - Train Loss: 2.3082, Val Loss: 2.3064\n",
      "Epoch 12/50 - Train Loss: 2.3091, Val Loss: 2.3066\n",
      "Epoch 13/50 - Train Loss: 2.3091, Val Loss: 2.3101\n",
      "Epoch 14/50 - Train Loss: 2.3088, Val Loss: 2.3124\n",
      "Epoch 15/50 - Train Loss: 2.3089, Val Loss: 2.3150\n",
      "Epoch 16/50 - Train Loss: 2.3092, Val Loss: 2.3063\n",
      "Epoch 17/50 - Train Loss: 2.3084, Val Loss: 2.3070\n",
      "Epoch 18/50 - Train Loss: 2.3091, Val Loss: 2.3115\n",
      "Epoch 19/50 - Train Loss: 2.3087, Val Loss: 2.3065\n",
      "Epoch 20/50 - Train Loss: 2.3086, Val Loss: 2.3176\n",
      "Epoch 21/50 - Train Loss: 2.3083, Val Loss: 2.3117\n",
      "Epoch 22/50 - Train Loss: 2.3094, Val Loss: 2.3068\n",
      "Epoch 23/50 - Train Loss: 2.3095, Val Loss: 2.3102\n",
      "Epoch 24/50 - Train Loss: 2.3088, Val Loss: 2.3068\n",
      "Epoch 25/50 - Train Loss: 2.3081, Val Loss: 2.3063\n",
      "Epoch 26/50 - Train Loss: 2.3088, Val Loss: 2.3025\n",
      "Epoch 27/50 - Train Loss: 2.3086, Val Loss: 2.3104\n",
      "Epoch 28/50 - Train Loss: 2.3083, Val Loss: 2.3139\n",
      "Epoch 29/50 - Train Loss: 2.3094, Val Loss: 2.3102\n",
      "Epoch 30/50 - Train Loss: 2.3091, Val Loss: 2.3076\n",
      "Epoch 31/50 - Train Loss: 2.3086, Val Loss: 2.3107\n",
      "Epoch 32/50 - Train Loss: 2.3086, Val Loss: 2.3112\n",
      "Epoch 33/50 - Train Loss: 2.3082, Val Loss: 2.3123\n",
      "Epoch 34/50 - Train Loss: 2.3091, Val Loss: 2.3062\n",
      "Epoch 35/50 - Train Loss: 2.3086, Val Loss: 2.3084\n",
      "Epoch 36/50 - Train Loss: 2.3084, Val Loss: 2.3110\n",
      "Epoch 37/50 - Train Loss: 2.3093, Val Loss: 2.3086\n",
      "Epoch 38/50 - Train Loss: 2.3088, Val Loss: 2.3111\n",
      "Epoch 39/50 - Train Loss: 2.3085, Val Loss: 2.3135\n",
      "Epoch 40/50 - Train Loss: 2.3089, Val Loss: 2.3131\n",
      "Epoch 41/50 - Train Loss: 2.3087, Val Loss: 2.3078\n",
      "Epoch 42/50 - Train Loss: 2.3086, Val Loss: 2.3102\n",
      "Epoch 43/50 - Train Loss: 2.3088, Val Loss: 2.3124\n",
      "Epoch 44/50 - Train Loss: 2.3089, Val Loss: 2.3088\n",
      "Epoch 45/50 - Train Loss: 2.3092, Val Loss: 2.3088\n",
      "Epoch 46/50 - Train Loss: 2.3088, Val Loss: 2.3151\n",
      "Epoch 47/50 - Train Loss: 2.3087, Val Loss: 2.3083\n",
      "Epoch 48/50 - Train Loss: 2.3088, Val Loss: 2.3130\n",
      "Epoch 49/50 - Train Loss: 2.3092, Val Loss: 2.3147\n",
      "Epoch 50/50 - Train Loss: 2.3087, Val Loss: 2.3188\n",
      "Learning Rate 0.01: Test Accuracy: 11.35%\n",
      "\n",
      "Best Learning Rate Configuration:\n",
      "Learning Rate: 0.001\n",
      "Test Accuracy: 97.32%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import struct\n",
    "from array import array\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mlp import MultilayerPerceptron, Layer, CrossEntropy, Relu, Softmax\n",
    "\n",
    "# -------------------- MNIST Data Loader Class -------------------- #\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    \"\"\"\n",
    "    A class to load and preprocess the MNIST dataset from IDX files.\n",
    "    \"\"\"\n",
    "    def __init__(self, training_images_filepath, training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        \"\"\"\n",
    "        Reads image and label data from IDX files.\n",
    "        \"\"\"\n",
    "        # Read labels\n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))  # Read magic number and size\n",
    "            if magic != 2049:\n",
    "                raise ValueError(f'Magic number mismatch, expected 2049, got {magic}')\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        # Read images\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))  # Read metadata\n",
    "            if magic != 2051:\n",
    "                raise ValueError(f'Magic number mismatch, expected 2051, got {magic}')\n",
    "            image_data = array(\"B\", file.read())  # Read pixel data        \n",
    "        \n",
    "        # Reshape image data into (size, 28, 28)\n",
    "        images = [np.array(image_data[i * rows * cols:(i + 1) * rows * cols]).reshape(28, 28) for i in range(size)]\n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads training and test datasets.\n",
    "        \"\"\"\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train), (x_test, y_test)  \n",
    "\n",
    "# -------------------- Reading Dataset via MnistDataloader class -------------------- #\n",
    "\n",
    "data_folder = 'MNIST-data/'  # Dataset directory\n",
    "\n",
    "# File paths for MNIST dataset\n",
    "training_images_filepath = os.path.join(data_folder, 'train-images.idx3-ubyte')\n",
    "training_labels_filepath = os.path.join(data_folder, 'train-labels.idx1-ubyte')\n",
    "test_images_filepath = os.path.join(data_folder, 't10k-images.idx3-ubyte')\n",
    "test_labels_filepath = os.path.join(data_folder, 't10k-labels.idx1-ubyte')\n",
    "\n",
    "# Loading MNIST dataset\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "# Converting lists to NumPy arrays and normalize pixel values\n",
    "x_train = np.array(x_train).reshape(-1, 784) / 255.0  # Normalize & flatten\n",
    "x_test = np.array(x_test).reshape(-1, 784) / 255.0\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Manual Train-Validation Split (80% train, 20% validation)\n",
    "split_idx = int(len(x_train) * 0.8)\n",
    "x_train, x_val = x_train[:split_idx], x_train[split_idx:]\n",
    "y_train, y_val = y_train[:split_idx], y_train[split_idx:]\n",
    "\n",
    "# Function to one-hot encode labels\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    one_hot = np.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot[i][label] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Converting labels to one-hot encoding\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_val = one_hot_encode(y_val)\n",
    "y_test = one_hot_encode(y_test)\n",
    "\n",
    "# Function to display sample images\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images) / cols) + 1\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    index = 1\n",
    "    for img, title in zip(images, title_texts):\n",
    "        plt.subplot(rows, cols, index)\n",
    "        plt.imshow(img, cmap=plt.cm.gray)\n",
    "        plt.title(title, fontsize=15)\n",
    "        index += 1\n",
    "\n",
    "# -------------------- MLP Architecture for MNIST Dataset -------------------- #\n",
    "\n",
    "# Define different learning rates to test\n",
    "learning_rates = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "\n",
    "# Fixed layer architecture for comparison\n",
    "fixed_layers = [\n",
    "    Layer(784, 128, Relu(), dropout_rate=0.2),\n",
    "    Layer(128, 128, Relu(), dropout_rate=0.2),\n",
    "    Layer(128, 10, Softmax())\n",
    "]\n",
    "\n",
    "# Store results of test accuracies\n",
    "results = {}\n",
    "\n",
    "# Loop through different learning rates\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    print(f\"\\nTraining with Learning Rate: {lr}\")\n",
    "\n",
    "    # Define the MLP model with fixed layers\n",
    "    mlp = MultilayerPerceptron(fixed_layers)\n",
    "\n",
    "    # Define loss function\n",
    "    loss_function = CrossEntropy()\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, val_losses = mlp.train(\n",
    "        x_train, y_train, x_val, y_val,\n",
    "        loss_function, learning_rate=lr,\n",
    "        batch_size=64, epochs=50, optimizer='vanilla', momentum=0.7\n",
    "    )\n",
    "\n",
    "    # Evaluating model on test set\n",
    "    y_pred = mlp.forward(x_test)\n",
    "    test_accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "    # Store the result\n",
    "    results[idx] = {\n",
    "        \"learning_rate\": lr,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"Learning Rate {lr}: Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Find the best learning rate based on test accuracy\n",
    "best_lr_idx = max(results, key=lambda x: results[x][\"test_accuracy\"])\n",
    "best_learning_rate = results[best_lr_idx]\n",
    "\n",
    "print(\"\\nBest Learning Rate Configuration:\")\n",
    "print(f\"Learning Rate: {best_learning_rate['learning_rate']}\")\n",
    "print(f\"Test Accuracy: {best_learning_rate['test_accuracy'] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
