{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.3071, Val Loss: 0.1562\n",
      "Epoch 2/50 - Train Loss: 0.1266, Val Loss: 0.1146\n",
      "Epoch 3/50 - Train Loss: 0.0875, Val Loss: 0.1041\n",
      "Epoch 4/50 - Train Loss: 0.0672, Val Loss: 0.0930\n",
      "Epoch 5/50 - Train Loss: 0.0523, Val Loss: 0.0847\n",
      "Epoch 6/50 - Train Loss: 0.0418, Val Loss: 0.0899\n",
      "Epoch 7/50 - Train Loss: 0.0324, Val Loss: 0.0924\n",
      "Epoch 8/50 - Train Loss: 0.0255, Val Loss: 0.0924\n",
      "Epoch 9/50 - Train Loss: 0.0211, Val Loss: 0.0853\n",
      "Epoch 10/50 - Train Loss: 0.0163, Val Loss: 0.0832\n",
      "Epoch 11/50 - Train Loss: 0.0121, Val Loss: 0.0879\n",
      "Epoch 12/50 - Train Loss: 0.0092, Val Loss: 0.0946\n",
      "Epoch 13/50 - Train Loss: 0.0063, Val Loss: 0.0988\n",
      "Epoch 14/50 - Train Loss: 0.0040, Val Loss: 0.0902\n",
      "Epoch 15/50 - Train Loss: 0.0021, Val Loss: 0.0913\n",
      "Epoch 16/50 - Train Loss: 0.0015, Val Loss: 0.0904\n",
      "Epoch 17/50 - Train Loss: 0.0012, Val Loss: 0.0920\n",
      "Epoch 18/50 - Train Loss: 0.0010, Val Loss: 0.0948\n",
      "Epoch 19/50 - Train Loss: 0.0009, Val Loss: 0.0940\n",
      "Epoch 20/50 - Train Loss: 0.0007, Val Loss: 0.0959\n",
      "Epoch 21/50 - Train Loss: 0.0006, Val Loss: 0.0963\n",
      "Epoch 22/50 - Train Loss: 0.0006, Val Loss: 0.0974\n",
      "Epoch 23/50 - Train Loss: 0.0005, Val Loss: 0.0975\n",
      "Epoch 24/50 - Train Loss: 0.0005, Val Loss: 0.0985\n",
      "Epoch 25/50 - Train Loss: 0.0005, Val Loss: 0.0993\n",
      "Epoch 26/50 - Train Loss: 0.0004, Val Loss: 0.0993\n",
      "Epoch 27/50 - Train Loss: 0.0004, Val Loss: 0.1002\n",
      "Epoch 28/50 - Train Loss: 0.0004, Val Loss: 0.1013\n",
      "Epoch 29/50 - Train Loss: 0.0004, Val Loss: 0.1014\n",
      "Epoch 30/50 - Train Loss: 0.0003, Val Loss: 0.1019\n",
      "Epoch 31/50 - Train Loss: 0.0003, Val Loss: 0.1036\n",
      "Epoch 32/50 - Train Loss: 0.0003, Val Loss: 0.1035\n",
      "Epoch 33/50 - Train Loss: 0.0003, Val Loss: 0.1032\n",
      "Epoch 34/50 - Train Loss: 0.0003, Val Loss: 0.1038\n",
      "Epoch 35/50 - Train Loss: 0.0003, Val Loss: 0.1044\n",
      "Epoch 36/50 - Train Loss: 0.0003, Val Loss: 0.1050\n",
      "Epoch 37/50 - Train Loss: 0.0003, Val Loss: 0.1052\n",
      "Epoch 38/50 - Train Loss: 0.0002, Val Loss: 0.1058\n",
      "Epoch 39/50 - Train Loss: 0.0002, Val Loss: 0.1060\n",
      "Epoch 40/50 - Train Loss: 0.0002, Val Loss: 0.1062\n",
      "Epoch 41/50 - Train Loss: 0.0002, Val Loss: 0.1072\n",
      "Epoch 42/50 - Train Loss: 0.0002, Val Loss: 0.1068\n",
      "Epoch 43/50 - Train Loss: 0.0002, Val Loss: 0.1076\n",
      "Epoch 44/50 - Train Loss: 0.0002, Val Loss: 0.1079\n",
      "Epoch 45/50 - Train Loss: 0.0002, Val Loss: 0.1082\n",
      "Epoch 46/50 - Train Loss: 0.0002, Val Loss: 0.1084\n",
      "Epoch 47/50 - Train Loss: 0.0002, Val Loss: 0.1088\n",
      "Epoch 48/50 - Train Loss: 0.0002, Val Loss: 0.1091\n",
      "Epoch 49/50 - Train Loss: 0.0002, Val Loss: 0.1095\n",
      "Epoch 50/50 - Train Loss: 0.0002, Val Loss: 0.1095\n",
      "Layer combination 1: Test Accuracy: 98.04%\n",
      "Epoch 1/50 - Train Loss: 0.3431, Val Loss: 0.1858\n",
      "Epoch 2/50 - Train Loss: 0.1560, Val Loss: 0.1377\n",
      "Epoch 3/50 - Train Loss: 0.1131, Val Loss: 0.1253\n",
      "Epoch 4/50 - Train Loss: 0.0919, Val Loss: 0.1171\n",
      "Epoch 5/50 - Train Loss: 0.0771, Val Loss: 0.1133\n",
      "Epoch 6/50 - Train Loss: 0.0675, Val Loss: 0.1048\n",
      "Epoch 7/50 - Train Loss: 0.0595, Val Loss: 0.1156\n",
      "Epoch 8/50 - Train Loss: 0.0509, Val Loss: 0.1127\n",
      "Epoch 9/50 - Train Loss: 0.0456, Val Loss: 0.1110\n",
      "Epoch 10/50 - Train Loss: 0.0430, Val Loss: 0.0996\n",
      "Epoch 11/50 - Train Loss: 0.0389, Val Loss: 0.1100\n",
      "Epoch 12/50 - Train Loss: 0.0395, Val Loss: 0.0947\n",
      "Epoch 13/50 - Train Loss: 0.0319, Val Loss: 0.0993\n",
      "Epoch 14/50 - Train Loss: 0.0320, Val Loss: 0.1067\n",
      "Epoch 15/50 - Train Loss: 0.0289, Val Loss: 0.1103\n",
      "Epoch 16/50 - Train Loss: 0.0274, Val Loss: 0.1047\n",
      "Epoch 17/50 - Train Loss: 0.0257, Val Loss: 0.1102\n",
      "Epoch 18/50 - Train Loss: 0.0247, Val Loss: 0.1146\n",
      "Epoch 19/50 - Train Loss: 0.0231, Val Loss: 0.1063\n",
      "Epoch 20/50 - Train Loss: 0.0228, Val Loss: 0.1058\n",
      "Epoch 21/50 - Train Loss: 0.0210, Val Loss: 0.1092\n",
      "Epoch 22/50 - Train Loss: 0.0178, Val Loss: 0.1174\n",
      "Epoch 23/50 - Train Loss: 0.0173, Val Loss: 0.1144\n",
      "Epoch 24/50 - Train Loss: 0.0171, Val Loss: 0.1141\n",
      "Epoch 25/50 - Train Loss: 0.0189, Val Loss: 0.1046\n",
      "Epoch 26/50 - Train Loss: 0.0174, Val Loss: 0.1134\n",
      "Epoch 27/50 - Train Loss: 0.0154, Val Loss: 0.1113\n",
      "Epoch 28/50 - Train Loss: 0.0144, Val Loss: 0.1172\n",
      "Epoch 29/50 - Train Loss: 0.0144, Val Loss: 0.1116\n",
      "Epoch 30/50 - Train Loss: 0.0133, Val Loss: 0.1109\n",
      "Epoch 31/50 - Train Loss: 0.0110, Val Loss: 0.1155\n",
      "Epoch 32/50 - Train Loss: 0.0135, Val Loss: 0.1238\n",
      "Epoch 33/50 - Train Loss: 0.0128, Val Loss: 0.1130\n",
      "Epoch 34/50 - Train Loss: 0.0124, Val Loss: 0.1051\n",
      "Epoch 35/50 - Train Loss: 0.0125, Val Loss: 0.1147\n",
      "Epoch 36/50 - Train Loss: 0.0120, Val Loss: 0.1142\n",
      "Epoch 37/50 - Train Loss: 0.0111, Val Loss: 0.1193\n",
      "Epoch 38/50 - Train Loss: 0.0118, Val Loss: 0.1261\n",
      "Epoch 39/50 - Train Loss: 0.0098, Val Loss: 0.1185\n",
      "Epoch 40/50 - Train Loss: 0.0120, Val Loss: 0.1173\n",
      "Epoch 41/50 - Train Loss: 0.0113, Val Loss: 0.1184\n",
      "Epoch 42/50 - Train Loss: 0.0107, Val Loss: 0.1153\n",
      "Epoch 43/50 - Train Loss: 0.0107, Val Loss: 0.1130\n",
      "Epoch 44/50 - Train Loss: 0.0113, Val Loss: 0.1265\n",
      "Epoch 45/50 - Train Loss: 0.0103, Val Loss: 0.1165\n",
      "Epoch 46/50 - Train Loss: 0.0095, Val Loss: 0.1258\n",
      "Epoch 47/50 - Train Loss: 0.0086, Val Loss: 0.1213\n",
      "Epoch 48/50 - Train Loss: 0.0093, Val Loss: 0.1221\n",
      "Epoch 49/50 - Train Loss: 0.0084, Val Loss: 0.1252\n",
      "Epoch 50/50 - Train Loss: 0.0109, Val Loss: 0.1213\n",
      "Layer combination 2: Test Accuracy: 97.58%\n",
      "Epoch 1/50 - Train Loss: 0.3889, Val Loss: 0.2218\n",
      "Epoch 2/50 - Train Loss: 0.1915, Val Loss: 0.1879\n",
      "Epoch 3/50 - Train Loss: 0.1460, Val Loss: 0.1442\n",
      "Epoch 4/50 - Train Loss: 0.1234, Val Loss: 0.1352\n",
      "Epoch 5/50 - Train Loss: 0.1075, Val Loss: 0.1282\n",
      "Epoch 6/50 - Train Loss: 0.0956, Val Loss: 0.1114\n",
      "Epoch 7/50 - Train Loss: 0.0888, Val Loss: 0.1251\n",
      "Epoch 8/50 - Train Loss: 0.0772, Val Loss: 0.1153\n",
      "Epoch 9/50 - Train Loss: 0.0728, Val Loss: 0.1133\n",
      "Epoch 10/50 - Train Loss: 0.0655, Val Loss: 0.1166\n",
      "Epoch 11/50 - Train Loss: 0.0647, Val Loss: 0.1133\n",
      "Epoch 12/50 - Train Loss: 0.0588, Val Loss: 0.1172\n",
      "Epoch 13/50 - Train Loss: 0.0555, Val Loss: 0.1166\n",
      "Epoch 14/50 - Train Loss: 0.0533, Val Loss: 0.1231\n",
      "Epoch 15/50 - Train Loss: 0.0531, Val Loss: 0.1233\n",
      "Epoch 16/50 - Train Loss: 0.0483, Val Loss: 0.1082\n",
      "Epoch 17/50 - Train Loss: 0.0474, Val Loss: 0.1153\n",
      "Epoch 18/50 - Train Loss: 0.0454, Val Loss: 0.1119\n",
      "Epoch 19/50 - Train Loss: 0.0418, Val Loss: 0.1191\n",
      "Epoch 20/50 - Train Loss: 0.0407, Val Loss: 0.1174\n",
      "Epoch 21/50 - Train Loss: 0.0392, Val Loss: 0.1206\n",
      "Epoch 22/50 - Train Loss: 0.0362, Val Loss: 0.1236\n",
      "Epoch 23/50 - Train Loss: 0.0358, Val Loss: 0.1252\n",
      "Epoch 24/50 - Train Loss: 0.0375, Val Loss: 0.1104\n",
      "Epoch 25/50 - Train Loss: 0.0345, Val Loss: 0.1169\n",
      "Epoch 26/50 - Train Loss: 0.0333, Val Loss: 0.1197\n",
      "Epoch 27/50 - Train Loss: 0.0331, Val Loss: 0.1241\n",
      "Epoch 28/50 - Train Loss: 0.0304, Val Loss: 0.1164\n",
      "Epoch 29/50 - Train Loss: 0.0310, Val Loss: 0.1204\n",
      "Epoch 30/50 - Train Loss: 0.0313, Val Loss: 0.1279\n",
      "Epoch 31/50 - Train Loss: 0.0297, Val Loss: 0.1220\n",
      "Epoch 32/50 - Train Loss: 0.0273, Val Loss: 0.1165\n",
      "Epoch 33/50 - Train Loss: 0.0284, Val Loss: 0.1234\n",
      "Epoch 34/50 - Train Loss: 0.0255, Val Loss: 0.1225\n",
      "Epoch 35/50 - Train Loss: 0.0259, Val Loss: 0.1135\n",
      "Epoch 36/50 - Train Loss: 0.0265, Val Loss: 0.1263\n",
      "Epoch 37/50 - Train Loss: 0.0269, Val Loss: 0.1173\n",
      "Epoch 38/50 - Train Loss: 0.0252, Val Loss: 0.1199\n",
      "Epoch 39/50 - Train Loss: 0.0252, Val Loss: 0.1159\n",
      "Epoch 40/50 - Train Loss: 0.0244, Val Loss: 0.1195\n",
      "Epoch 41/50 - Train Loss: 0.0239, Val Loss: 0.1222\n",
      "Epoch 42/50 - Train Loss: 0.0228, Val Loss: 0.1175\n",
      "Epoch 43/50 - Train Loss: 0.0222, Val Loss: 0.1240\n",
      "Epoch 44/50 - Train Loss: 0.0231, Val Loss: 0.1262\n",
      "Epoch 45/50 - Train Loss: 0.0212, Val Loss: 0.1244\n",
      "Epoch 46/50 - Train Loss: 0.0203, Val Loss: 0.1229\n",
      "Epoch 47/50 - Train Loss: 0.0205, Val Loss: 0.1237\n",
      "Epoch 48/50 - Train Loss: 0.0192, Val Loss: 0.1177\n",
      "Epoch 49/50 - Train Loss: 0.0212, Val Loss: 0.1286\n",
      "Epoch 50/50 - Train Loss: 0.0207, Val Loss: 0.1284\n",
      "Layer combination 3: Test Accuracy: 97.43%\n",
      "Epoch 1/50 - Train Loss: 0.4450, Val Loss: 0.2494\n",
      "Epoch 2/50 - Train Loss: 0.2277, Val Loss: 0.1953\n",
      "Epoch 3/50 - Train Loss: 0.1847, Val Loss: 0.1870\n",
      "Epoch 4/50 - Train Loss: 0.1561, Val Loss: 0.1614\n",
      "Epoch 5/50 - Train Loss: 0.1396, Val Loss: 0.1683\n",
      "Epoch 6/50 - Train Loss: 0.1269, Val Loss: 0.1432\n",
      "Epoch 7/50 - Train Loss: 0.1172, Val Loss: 0.1396\n",
      "Epoch 8/50 - Train Loss: 0.1092, Val Loss: 0.1329\n",
      "Epoch 9/50 - Train Loss: 0.1025, Val Loss: 0.1349\n",
      "Epoch 10/50 - Train Loss: 0.0962, Val Loss: 0.1342\n",
      "Epoch 11/50 - Train Loss: 0.0898, Val Loss: 0.1344\n",
      "Epoch 12/50 - Train Loss: 0.0850, Val Loss: 0.1391\n",
      "Epoch 13/50 - Train Loss: 0.0837, Val Loss: 0.1351\n",
      "Epoch 14/50 - Train Loss: 0.0828, Val Loss: 0.1350\n",
      "Epoch 15/50 - Train Loss: 0.0774, Val Loss: 0.1422\n",
      "Epoch 16/50 - Train Loss: 0.0747, Val Loss: 0.1340\n",
      "Epoch 17/50 - Train Loss: 0.0724, Val Loss: 0.1260\n",
      "Epoch 18/50 - Train Loss: 0.0700, Val Loss: 0.1303\n",
      "Epoch 19/50 - Train Loss: 0.0659, Val Loss: 0.1359\n",
      "Epoch 20/50 - Train Loss: 0.0667, Val Loss: 0.1232\n",
      "Epoch 21/50 - Train Loss: 0.0617, Val Loss: 0.1314\n",
      "Epoch 22/50 - Train Loss: 0.0621, Val Loss: 0.1265\n",
      "Epoch 23/50 - Train Loss: 0.0611, Val Loss: 0.1323\n",
      "Epoch 24/50 - Train Loss: 0.0609, Val Loss: 0.1307\n",
      "Epoch 25/50 - Train Loss: 0.0591, Val Loss: 0.1305\n",
      "Epoch 26/50 - Train Loss: 0.0555, Val Loss: 0.1231\n",
      "Epoch 27/50 - Train Loss: 0.0580, Val Loss: 0.1252\n",
      "Epoch 28/50 - Train Loss: 0.0548, Val Loss: 0.1356\n",
      "Epoch 29/50 - Train Loss: 0.0526, Val Loss: 0.1236\n",
      "Epoch 30/50 - Train Loss: 0.0532, Val Loss: 0.1371\n",
      "Epoch 31/50 - Train Loss: 0.0534, Val Loss: 0.1272\n",
      "Epoch 32/50 - Train Loss: 0.0504, Val Loss: 0.1246\n",
      "Epoch 33/50 - Train Loss: 0.0507, Val Loss: 0.1329\n",
      "Epoch 34/50 - Train Loss: 0.0526, Val Loss: 0.1327\n",
      "Epoch 35/50 - Train Loss: 0.0478, Val Loss: 0.1358\n",
      "Epoch 36/50 - Train Loss: 0.0462, Val Loss: 0.1316\n",
      "Epoch 37/50 - Train Loss: 0.0451, Val Loss: 0.1338\n",
      "Epoch 38/50 - Train Loss: 0.0447, Val Loss: 0.1284\n",
      "Epoch 39/50 - Train Loss: 0.0445, Val Loss: 0.1240\n",
      "Epoch 40/50 - Train Loss: 0.0452, Val Loss: 0.1428\n",
      "Epoch 41/50 - Train Loss: 0.0461, Val Loss: 0.1453\n",
      "Epoch 42/50 - Train Loss: 0.0461, Val Loss: 0.1332\n",
      "Epoch 43/50 - Train Loss: 0.0419, Val Loss: 0.1314\n",
      "Epoch 44/50 - Train Loss: 0.0415, Val Loss: 0.1312\n",
      "Epoch 45/50 - Train Loss: 0.0410, Val Loss: 0.1279\n",
      "Epoch 46/50 - Train Loss: 0.0411, Val Loss: 0.1455\n",
      "Epoch 47/50 - Train Loss: 0.0411, Val Loss: 0.1380\n",
      "Epoch 48/50 - Train Loss: 0.0412, Val Loss: 0.1308\n",
      "Epoch 49/50 - Train Loss: 0.0419, Val Loss: 0.1351\n",
      "Epoch 50/50 - Train Loss: 0.0406, Val Loss: 0.1354\n",
      "Layer combination 4: Test Accuracy: 96.82%\n",
      "Epoch 1/50 - Train Loss: 0.5987, Val Loss: 0.3695\n",
      "Epoch 2/50 - Train Loss: 0.3376, Val Loss: 0.2794\n",
      "Epoch 3/50 - Train Loss: 0.2889, Val Loss: 0.2628\n",
      "Epoch 4/50 - Train Loss: 0.2594, Val Loss: 0.2452\n",
      "Epoch 5/50 - Train Loss: 0.2343, Val Loss: 0.2366\n",
      "Epoch 6/50 - Train Loss: 0.2209, Val Loss: 0.2202\n",
      "Epoch 7/50 - Train Loss: 0.2133, Val Loss: 0.2170\n",
      "Epoch 8/50 - Train Loss: 0.1983, Val Loss: 0.2297\n",
      "Epoch 9/50 - Train Loss: 0.1932, Val Loss: 0.2113\n",
      "Epoch 10/50 - Train Loss: 0.1853, Val Loss: 0.2100\n",
      "Epoch 11/50 - Train Loss: 0.1760, Val Loss: 0.2104\n",
      "Epoch 12/50 - Train Loss: 0.1751, Val Loss: 0.2018\n",
      "Epoch 13/50 - Train Loss: 0.1700, Val Loss: 0.2107\n",
      "Epoch 14/50 - Train Loss: 0.1630, Val Loss: 0.1998\n",
      "Epoch 15/50 - Train Loss: 0.1630, Val Loss: 0.1925\n",
      "Epoch 16/50 - Train Loss: 0.1574, Val Loss: 0.1928\n",
      "Epoch 17/50 - Train Loss: 0.1585, Val Loss: 0.1988\n",
      "Epoch 18/50 - Train Loss: 0.1563, Val Loss: 0.2033\n",
      "Epoch 19/50 - Train Loss: 0.1540, Val Loss: 0.1974\n",
      "Epoch 20/50 - Train Loss: 0.1506, Val Loss: 0.1960\n",
      "Epoch 21/50 - Train Loss: 0.1447, Val Loss: 0.1848\n",
      "Epoch 22/50 - Train Loss: 0.1424, Val Loss: 0.1874\n",
      "Epoch 23/50 - Train Loss: 0.1421, Val Loss: 0.1931\n",
      "Epoch 24/50 - Train Loss: 0.1411, Val Loss: 0.1963\n",
      "Epoch 25/50 - Train Loss: 0.1418, Val Loss: 0.1913\n",
      "Epoch 26/50 - Train Loss: 0.1397, Val Loss: 0.1894\n",
      "Epoch 27/50 - Train Loss: 0.1329, Val Loss: 0.1891\n",
      "Epoch 28/50 - Train Loss: 0.1333, Val Loss: 0.1907\n",
      "Epoch 29/50 - Train Loss: 0.1362, Val Loss: 0.1927\n",
      "Epoch 30/50 - Train Loss: 0.1297, Val Loss: 0.1942\n",
      "Epoch 31/50 - Train Loss: 0.1322, Val Loss: 0.1781\n",
      "Epoch 32/50 - Train Loss: 0.1275, Val Loss: 0.1887\n",
      "Epoch 33/50 - Train Loss: 0.1271, Val Loss: 0.1995\n",
      "Epoch 34/50 - Train Loss: 0.1231, Val Loss: 0.1953\n",
      "Epoch 35/50 - Train Loss: 0.1230, Val Loss: 0.1851\n",
      "Epoch 36/50 - Train Loss: 0.1238, Val Loss: 0.1955\n",
      "Epoch 37/50 - Train Loss: 0.1246, Val Loss: 0.1914\n",
      "Epoch 38/50 - Train Loss: 0.1228, Val Loss: 0.1925\n",
      "Epoch 39/50 - Train Loss: 0.1187, Val Loss: 0.1809\n",
      "Epoch 40/50 - Train Loss: 0.1198, Val Loss: 0.1882\n",
      "Epoch 41/50 - Train Loss: 0.1205, Val Loss: 0.1909\n",
      "Epoch 42/50 - Train Loss: 0.1245, Val Loss: 0.1780\n",
      "Epoch 43/50 - Train Loss: 0.1196, Val Loss: 0.1839\n",
      "Epoch 44/50 - Train Loss: 0.1183, Val Loss: 0.1915\n",
      "Epoch 45/50 - Train Loss: 0.1157, Val Loss: 0.1839\n",
      "Epoch 46/50 - Train Loss: 0.1167, Val Loss: 0.1911\n",
      "Epoch 47/50 - Train Loss: 0.1148, Val Loss: 0.1821\n",
      "Epoch 48/50 - Train Loss: 0.1152, Val Loss: 0.1877\n",
      "Epoch 49/50 - Train Loss: 0.1063, Val Loss: 0.1903\n",
      "Epoch 50/50 - Train Loss: 0.1124, Val Loss: 0.2033\n",
      "Layer combination 5: Test Accuracy: 95.05%\n",
      "\n",
      "Best Layer Combination:\n",
      "Combination Number: 1\n",
      "Test Accuracy: 98.04%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import struct\n",
    "from array import array\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mlp import MultilayerPerceptron, Layer, CrossEntropy, Relu, Softmax\n",
    "\n",
    "# -------------------- MNIST Data Loader Class -------------------- #\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    \"\"\"\n",
    "    A class to load and preprocess the MNIST dataset from IDX files.\n",
    "    \"\"\"\n",
    "    def __init__(self, training_images_filepath, training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        \"\"\"\n",
    "        Reads image and label data from IDX files.\n",
    "        \"\"\"\n",
    "        # Read labels\n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))  # Read magic number and size\n",
    "            if magic != 2049:\n",
    "                raise ValueError(f'Magic number mismatch, expected 2049, got {magic}')\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        # Read images\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))  # Read metadata\n",
    "            if magic != 2051:\n",
    "                raise ValueError(f'Magic number mismatch, expected 2051, got {magic}')\n",
    "            image_data = array(\"B\", file.read())  # Read pixel data        \n",
    "        \n",
    "        # Reshape image data into (size, 28, 28)\n",
    "        images = [np.array(image_data[i * rows * cols:(i + 1) * rows * cols]).reshape(28, 28) for i in range(size)]\n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads training and test datasets.\n",
    "        \"\"\"\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train), (x_test, y_test)  \n",
    "\n",
    "# -------------------- Reading Dataset via MnistDataloader class -------------------- #\n",
    "\n",
    "data_folder = 'MNIST-data/'  # Dataset directory\n",
    "\n",
    "# File paths for MNIST dataset\n",
    "training_images_filepath = os.path.join(data_folder, 'train-images.idx3-ubyte')\n",
    "training_labels_filepath = os.path.join(data_folder, 'train-labels.idx1-ubyte')\n",
    "test_images_filepath = os.path.join(data_folder, 't10k-images.idx3-ubyte')\n",
    "test_labels_filepath = os.path.join(data_folder, 't10k-labels.idx1-ubyte')\n",
    "\n",
    "# Loading MNIST dataset\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "# Converting lists to NumPy arrays and normalize pixel values\n",
    "x_train = np.array(x_train).reshape(-1, 784) / 255.0  # Normalize & flatten\n",
    "x_test = np.array(x_test).reshape(-1, 784) / 255.0\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Manual Train-Validation Split (80% train, 20% validation)\n",
    "split_idx = int(len(x_train) * 0.8)\n",
    "x_train, x_val = x_train[:split_idx], x_train[split_idx:]\n",
    "y_train, y_val = y_train[:split_idx], y_train[split_idx:]\n",
    "\n",
    "# Function to one-hot encode labels\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    one_hot = np.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot[i][label] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Converting labels to one-hot encoding\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_val = one_hot_encode(y_val)\n",
    "y_test = one_hot_encode(y_test)\n",
    "\n",
    "# Function to display sample images\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images) / cols) + 1\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    index = 1\n",
    "    for img, title in zip(images, title_texts):\n",
    "        plt.subplot(rows, cols, index)\n",
    "        plt.imshow(img, cmap=plt.cm.gray)\n",
    "        plt.title(title, fontsize=15)\n",
    "        index += 1\n",
    "\n",
    "# -------------------- MLP Architecture for MNIST Dataset -------------------- #\n",
    "\n",
    "# Define different layer combinations\n",
    "layer_combinations = [\n",
    "    [Layer(784, 128, Relu(), dropout_rate=0.0), Layer(128, 128, Relu(), dropout_rate=0.0), Layer(128, 10, Softmax())],  # No dropout\n",
    "    [Layer(784, 128, Relu(), dropout_rate=0.1), Layer(128, 128, Relu(), dropout_rate=0.1), Layer(128, 10, Softmax())],  # Dropout 0.1\n",
    "    [Layer(784, 128, Relu(), dropout_rate=0.2), Layer(128, 128, Relu(), dropout_rate=0.2), Layer(128, 10, Softmax())],  # Dropout 0.2\n",
    "    [Layer(784, 128, Relu(), dropout_rate=0.3), Layer(128, 128, Relu(), dropout_rate=0.3), Layer(128, 10, Softmax())],  # Dropout 0.3\n",
    "    [Layer(784, 128, Relu(), dropout_rate=0.5), Layer(128, 128, Relu(), dropout_rate=0.5), Layer(128, 10, Softmax())]   # Dropout 0.5 (Strong Regularization)\n",
    "]\n",
    "\n",
    "# Store results of test accuracies\n",
    "results = {}\n",
    "\n",
    "# Loop through different layer combinations\n",
    "for idx, layers in enumerate(layer_combinations):\n",
    "    # Defining the MLP model with the given layers\n",
    "    mlp = MultilayerPerceptron(layers)\n",
    "\n",
    "    # Defining loss function\n",
    "    loss_function = CrossEntropy()\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, val_losses = mlp.train(\n",
    "        x_train, y_train, x_val, y_val,\n",
    "        loss_function, learning_rate=0.001,\n",
    "        batch_size=64, epochs=50, optimizer='vanilla', momentum=0.7\n",
    "    )\n",
    "\n",
    "    # Evaluating model on test set\n",
    "    y_pred = mlp.forward(x_test)\n",
    "    test_accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "    # Store the result\n",
    "    results[idx] = {\n",
    "        \"layers\": layers,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"Layer combination {idx+1}: Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Find the best layer combination based on test accuracy\n",
    "best_combination_idx = max(results, key=lambda x: results[x][\"test_accuracy\"])\n",
    "best_combination = results[best_combination_idx]\n",
    "\n",
    "print(\"\\nBest Layer Combination:\")\n",
    "print(f\"Combination Number: {best_combination_idx + 1}\")  # Adding 1 to make it human-readable (starts from 1)\n",
    "print(f\"Test Accuracy: {best_combination['test_accuracy'] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
